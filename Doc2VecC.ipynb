{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Doc2VecC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgN0XNtU08glKH2JYGYIIO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matbun/Doc2vecC/blob/main/Doc2VecC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup env"
      ],
      "metadata": {
        "id": "sIuQQMjXKCA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cmake --upgrade"
      ],
      "metadata": {
        "id": "bBbdDLd8xr_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e211612-6fbe-4b21-c32c-e31a9e8f7211"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cmake in /usr/local/lib/python3.7/dist-packages (3.12.0)\n",
            "Collecting cmake\n",
            "  Downloading cmake-3.22.1-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.7 MB 1.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: cmake\n",
            "  Attempting uninstall: cmake\n",
            "    Found existing installation: cmake 3.12.0\n",
            "    Uninstalling cmake-3.12.0:\n",
            "      Successfully uninstalled cmake-3.12.0\n",
            "Successfully installed cmake-3.22.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9aXyD-PwtgEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4862fd2-c5c3-4d7d-c1b0-f6bded8c1a1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Doc2VecC'...\n",
            "remote: Enumerating objects: 241, done.\u001b[K\n",
            "remote: Counting objects: 100% (241/241), done.\u001b[K\n",
            "remote: Compressing objects: 100% (146/146), done.\u001b[K\n",
            "remote: Total 241 (delta 146), reused 177 (delta 89), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (241/241), 291.17 KiB | 2.53 MiB/s, done.\n",
            "Resolving deltas: 100% (146/146), done.\n",
            "/content/Doc2VecC/build\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- The CUDA compiler identification is NVIDIA 11.1.105\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Detecting CUDA compiler ABI info\n",
            "-- Detecting CUDA compiler ABI info - done\n",
            "-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
            "-- Detecting CUDA compile features\n",
            "-- Detecting CUDA compile features - done\n",
            "-- Found CUDAToolkit: /usr/local/cuda/include (found version \"11.1.105\") \n",
            "-- Looking for C++ include pthread.h\n",
            "-- Looking for C++ include pthread.h - found\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\n",
            "-- Looking for pthread_create in pthreads\n",
            "-- Looking for pthread_create in pthreads - not found\n",
            "-- Looking for pthread_create in pthread\n",
            "-- Looking for pthread_create in pthread - found\n",
            "-- Found Threads: TRUE  \n",
            "-- Performing Test COMPILER_SUPPORTS_MARCH_NATIVE\n",
            "-- Performing Test COMPILER_SUPPORTS_MARCH_NATIVE - Success\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/Doc2VecC/build\n",
            "[ 12%] \u001b[32mBuilding CUDA object CMakeFiles/doc2vecc_lib.dir/model.cu.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/doc2vecc_lib.dir/utils/arg_parser.cpp.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object CMakeFiles/doc2vecc_lib.dir/components/vocab.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CUDA object CMakeFiles/doc2vecc_lib.dir/libs/huffman.cu.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CUDA object CMakeFiles/doc2vecc_lib.dir/libs/unigram.cu.o\u001b[0m\n",
            "[ 75%] \u001b[32m\u001b[1mLinking CXX static library libdoc2vecc_lib.a\u001b[0m\n",
            "[ 75%] Built target doc2vecc_lib\n",
            "[ 87%] \u001b[32mBuilding CXX object CMakeFiles/doc2vecc.dir/doc2vecc.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable doc2vecc\u001b[0m\n",
            "[100%] Built target doc2vecc\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/oToToT/Doc2VecC\n",
        "%cd Doc2VecC/build\n",
        "!cmake -DCMAKE_BUILD_TYPE=Release .. && cmake --build .\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Doc2vecC"
      ],
      "metadata": {
        "id": "8ZB6puJSJlQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./build/doc2vecc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5JIbq051pRI",
        "outputId": "d92f9d81-a77c-4dc9-fbd7-baafe757a414"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU accelerated Doc2VecC implementation\n",
            "\n",
            "Options:\n",
            "Parameters for training:\n",
            "\t-train <file>\n",
            "\t\tUse text data from <file> to train the model; default is data.txt\n",
            "\t-word <file>\n",
            "\t\tUse <file> to save the resulting word vectors; default is wordvec.txt\n",
            "\t-output <file>\n",
            "\t\tUse <file> to save the resulting document vectors; default is docvec.txt\n",
            "\t-test <file>\n",
            "\t\tPredict text data from <file> with model; default is test.txt\n",
            "\t-size <int>\n",
            "\t\tSet size of word vectors; default is 100\n",
            "\t-window <int>\n",
            "\t\tSet max skip length between words; default is 5\n",
            "\t-sample <float>\n",
            "\t\tSet threshold for occurrence of words. Those that appear with higher frequency in the training data\n",
            "\t\twill be randomly down-sampled; default is 1e-3, useful range is (0, 1e-5)\n",
            "\t-hs <int>\n",
            "\t\tUse Hierarchical Softmax; default is 0 (not used)\n",
            "\t-negative <int>\n",
            "\t\tNumber of negative examples; default is 5, common values are 3 - 10 (0 = not used)\n",
            "\t-iter <int>\n",
            "\t\tRun more training iterations (default 10)\n",
            "\t-min-count <int>\n",
            "\t\tThis will discard words that appear less than <int> times; default is 5\n",
            "\t-alpha <float>\n",
            "\t\tSet the starting learning rate; default is 0.025 for skip-gram and 0.05 for CBOW\n",
            "\t-debug <int>\n",
            "\t\tSet the debug mode (default = 2 = more info during training)\n",
            "\t-binary <int>\n",
            "\t\tSave the resulting vectors in binary moded; default is 0 (off)\n",
            "\t-save-vocab <file>\n",
            "\t\tThe vocabulary will be saved to <file>\n",
            "\t-read-vocab <file>\n",
            "\t\tThe vocabulary will be read from <file>, not constructed from the training data\n",
            "\t-cbow <int>\n",
            "\t\tUse the continuous bag of words model; default is 1 (use 0 for skip-gram model)\n",
            "\t-sentence-sample <float>\n",
            "\t\tThe rate to sample words out of a document for documenet representation; default is 0.1\n",
            "    -vocab-limit <int>\n",
            "        The size limit of vocabulary dictionary; default is 21000000\n",
            "\n",
            "Examples:\n",
            "./doc2vecc -train data.txt -output docvec.txt -word wordvec.txt -sentence-sample 0.1 -size 200 -window 5 -sample 1e-4 -negative 5 -hs 0 -binary 0 -cbow 1 -iter 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./test.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NwAP4km78mg",
        "outputId": "00c53f25-e8b5-492c-85c2-248e77b37e03"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-18 12:26:21--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  19.3MB/s    in 6.8s    \n",
            "\n",
            "2022-01-18 12:26:28 (11.7 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/Doc2VecC/build\n",
            "\u001b[35m\u001b[1mConsolidate compiler generated dependencies of target doc2vecc_lib\u001b[0m\n",
            "[ 75%] Built target doc2vecc_lib\n",
            "\u001b[35m\u001b[1mConsolidate compiler generated dependencies of target doc2vecc\u001b[0m\n",
            "[100%] Built target doc2vecc\n",
            "Vocab size: 43374      \n",
            "Words in train file: 26299251\n",
            "Building Huffman Tree.\n",
            "Converting train file to indices.\n",
            "Total Size: 202258 KiB\n",
            "training epoch 0                 \n",
            "training epoch 1                 \n",
            "training epoch 2                 \n",
            "training epoch 3                 \n",
            "training epoch 4                 \n",
            "training epoch 5                 \n",
            "training epoch 6                 \n",
            "training epoch 7                 \n",
            "training epoch 8                 \n",
            "training epoch 9                 \n",
            "training epoch 10                 \n",
            "training epoch 11                 \n",
            "training epoch 12                 \n",
            "training epoch 13                 \n",
            "training epoch 14                 \n",
            "training epoch 15                 \n",
            "training epoch 16                 \n",
            "training epoch 17                 \n",
            "training epoch 18                 \n",
            "training epoch 19                 \n",
            "Converting train file to indices.\n",
            "Total Size: 202258 KiB\n",
            "\n",
            "real\t55m32.696s\n",
            "user\t39m33.738s\n",
            "sys\t12m12.259s\n",
            "head: cannot open 'docvectors.txt' for reading: No such file or directory\n",
            "tail: cannot open 'docvectors.txt' for reading: No such file or directory\n"
          ]
        }
      ]
    }
  ]
}